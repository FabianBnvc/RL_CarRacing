{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/andywu0913/OpenAI-GYM-CarRacing-DQN/tree/master\n",
    "# https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import gym\n",
    "from collections import deque\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "from agent import Agent\n",
    "from processing import process_state_image, generate_state_frame_stack_from_queue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "render = True\n",
    "episodes = 50\n",
    "frame_stack_num = 4\n",
    "memory_size = 10000\n",
    "gamma = 0.99\n",
    "epsilon = 1.0\n",
    "epsilon_min = 0.01\n",
    "epsilon_decay = 0.995\n",
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "update_target_every = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CarRacing-v2', render_mode='rgb_array', continuous=False)\n",
    "# action_space, frame_stack_num, memmory_size, gamma, epsilon, epsilon_min, epsilon_decay, learning_rate\n",
    "agent = Agent(\n",
    "    action_space = env.action_space, \n",
    "    frame_stack_num = frame_stack_num,\n",
    "    memory_size = memory_size,\n",
    "    gamma = gamma,\n",
    "    epsilon = epsilon,\n",
    "    epsilon_min = epsilon_min,\n",
    "    epsilon_decay = epsilon_decay,\n",
    "    learning_rate = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Episodes: 100%|██████████| 50/50 [06:53<00:00,  8.28s/it, Total reward=-0.00614]\n"
     ]
    }
   ],
   "source": [
    "progress_bar = tqdm(total=episodes, desc=\"Episodes\")\n",
    "\n",
    "best_reward = float('-inf')\n",
    "\n",
    "for e in range(episodes):\n",
    "    state, info = env.reset(seed=77)\n",
    "    init_state = process_state_image(state)\n",
    "\n",
    "    total_reward = 0\n",
    "    negative_reward_counter = 0\n",
    "    state_frame_stack_queue = deque([init_state] * agent.frame_stack_num, maxlen=agent.frame_stack_num)\n",
    "    time_frame_counter = 1\n",
    "    \n",
    "    while True:\n",
    "        current_state_frame_stack = generate_state_frame_stack_from_queue(state_frame_stack_queue)\n",
    "        action = agent.act(current_state_frame_stack)\n",
    "\n",
    "        reward = 0\n",
    "        for _ in range(frame_stack_num-1):\n",
    "            next_state, r, terminated, truncated, info = env.step(action)\n",
    "            if terminated or truncated:\n",
    "                done = True\n",
    "            else: \n",
    "                done = False\n",
    "            reward += r\n",
    "            if done:\n",
    "                break\n",
    "        \n",
    "        # Counts the number of negative rewards in a row\n",
    "        negative_reward_counter = negative_reward_counter + 1 if time_frame_counter > 100 and reward < 0 else 0\n",
    "\n",
    "        # Extra bonus for the model if it uses full gas\n",
    "        # actions = do nothing, steer left, steer right, gas, brake\n",
    "        if action == 3:\n",
    "            reward *= 1.5\n",
    "        \n",
    "        total_reward += reward\n",
    "        if total_reward > best_reward:\n",
    "            best_reward = total_reward\n",
    "\n",
    "        next_state = process_state_image(next_state)\n",
    "        state_frame_stack_queue.append(next_state)\n",
    "        next_state_frame_stack = generate_state_frame_stack_from_queue(state_frame_stack_queue)\n",
    "\n",
    "        agent.memorize(current_state_frame_stack, action, reward, next_state_frame_stack, done)\n",
    "\n",
    "        if done or negative_reward_counter >= 25 or total_reward < 0:\n",
    "            progress_bar.set_postfix({\"Total reward\": total_reward, \"Best reward\": best_reward})\n",
    "            progress_bar.update(1)\n",
    "            break\n",
    "        if len(agent.memory) > batch_size:\n",
    "            agent.replay(batch_size)\n",
    "        time_frame_counter += 1\n",
    "\n",
    "    if e % update_target_every == 0:\n",
    "        agent.update_target_model()\n",
    "\n",
    "progress_bar.close()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(env, agent, seed=77):\n",
    "    state, info = env.reset(seed=seed)\n",
    "    env = gym.wrappers.RecordVideo(env=env, video_folder=\"../Videos\", name_prefix=\"test\", episode_trigger=lambda x: x % 2 == 0)\n",
    "\n",
    "    init_state = process_state_image(state)\n",
    "\n",
    "    state_frame_stack_queue = deque([init_state] * agent.frame_stack_num, maxlen=agent.frame_stack_num)\n",
    "    total_reward = 0\n",
    "\n",
    "    while True:\n",
    "        current_state_frame_stack = generate_state_frame_stack_from_queue(state_frame_stack_queue)\n",
    "        action = agent.act(current_state_frame_stack)\n",
    "\n",
    "        reward = 0\n",
    "        for _ in range(frame_stack_num-1):\n",
    "            next_state, r, terminated, truncated, info = env.step(action)\n",
    "            if terminated or truncated:\n",
    "                done = True\n",
    "            else:\n",
    "                done = False\n",
    "            reward += r\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "        total_reward += reward\n",
    "\n",
    "        next_state = process_state_image(next_state)\n",
    "        state_frame_stack_queue.append(next_state)\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    print(f\"Total reward after playing the game once: {total_reward}\")\n",
    "    env.close()\n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\fabia\\anaconda3\\envs\\car\\lib\\site-packages\\gym\\wrappers\\record_video.py:75: UserWarning: \u001b[33mWARN: Overwriting existing videos at c:\\Users\\fabia\\Desktop\\Studium\\RL\\RL_CarRacing\\Videos folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video c:\\Users\\fabia\\Desktop\\Studium\\RL\\RL_CarRacing\\Videos\\test-episode-0.mp4.\n",
      "Moviepy - Writing video c:\\Users\\fabia\\Desktop\\Studium\\RL\\RL_CarRacing\\Videos\\test-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready c:\\Users\\fabia\\Desktop\\Studium\\RL\\RL_CarRacing\\Videos\\test-episode-0.mp4\n",
      "Total reward after playing the game once: -75.43859649122798\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-75.43859649122798"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing(env, agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "car",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
